Load data fromkeras.datasets and perform following computational analysis:- [CO3]

(a) Preprocessing of the Data

(b) Divide data into training and testing data set

(c) Build the Gated Recurrent Units (GRU) Model

(d) Training the GRU Model

(e) Text Generation Using the Trained Model

(f) Evaluate Model’s accuracy

import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# Parameters
max_words = 10000  # Maximum number of words to consider as features
maxlen = 100       # Cut texts after this number of words (among top max_words most common words)

# Load data
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words)

# Pad sequences to ensure equal length
x_train = pad_sequences(x_train, maxlen=maxlen)
x_test = pad_sequences(x_test, maxlen=maxlen)

# One-hot encode the labels
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Function to create an LSTM model
def create_lstm_model():
    model = Sequential()
    model.add(Embedding(max_words, 128, input_length=maxlen))
    model.add(LSTM(128))
    model.add(Dropout(0.5))
    model.add(Dense(2, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Function to create a GRU model
def create_gru_model():
    model = Sequential()
    model.add(Embedding(max_words, 128, input_length=maxlen))
    model.add(GRU(128))
    model.add(Dropout(0.5))
    model.add(Dense(2, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Train the LSTM model
lstm_model = create_lstm_model()
lstm_history = lstm_model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2, verbose=1)

# Evaluate the LSTM model
lstm_loss, lstm_accuracy = lstm_model.evaluate(x_test, y_test, verbose=0)
print(f'LSTM Model Accuracy: {lstm_accuracy:.4f}')

# Train the GRU model
gru_model = create_gru_model()
gru_history = gru_model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2, verbose=1)

# Evaluate the GRU model
gru_loss, gru_accuracy = gru_model.evaluate(x_test, y_test, verbose=0)
print(f'GRU Model Accuracy: {gru_accuracy:.4f}')

# Function to plot training history
def plot_history(history, model_name):
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title(f'{model_name} Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()

# Plot training history for both models
plot_history(lstm_history, 'LSTM')
plot_history(gru_history, 'GRU')
Epoch 1/5
/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.
  warnings.warn(
157/157 ━━━━━━━━━━━━━━━━━━━━ 67s 411ms/step - accuracy: 0.6904 - loss: 0.5555 - val_accuracy: 0.8460 - val_loss: 0.3554
Epoch 2/5
157/157 ━━━━━━━━━━━━━━━━━━━━ 64s 406ms/step - accuracy: 0.8988 - loss: 0.2570 - val_accuracy: 0.8442 - val_loss: 0.3718
Epoch 3/5
157/157 ━━━━━━━━━━━━━━━━━━━━ 81s 399ms/step - accuracy: 0.9290 - loss: 0.1948 - val_accuracy: 0.8416 - val_loss: 0.4014
Epoch 4/5
157/157 ━━━━━━━━━━━━━━━━━━━━ 82s 401ms/step - accuracy: 0.9556 - loss: 0.1249 - val_accuracy: 0.8266 - val_loss: 0.4270
Epoch 5/5
157/157 ━━━━━━━━━━━━━━━━━━━━ 80s 389ms/step - accuracy: 0.9644 - loss: 0.0978 - val_accuracy: 0.8332 - val_loss: 0.6461
LSTM Model Accuracy: 0.8271
Epoch 1/5
157/157 ━━━━━━━━━━━━━━━━━━━━ 69s 427ms/step - accuracy: 0.6607 - loss: 0.5837 - val_accuracy: 0.8274 - val_loss: 0.3803
Epoch 2/5
157/157 ━━━━━━━━━━━━━━━━━━━━ 66s 423ms/step - accuracy: 0.8856 - loss: 0.2792 - val_accuracy: 0.8150 - val_loss: 0.4000
Epoch 3/5
157/157 ━━━━━━━━━━━━━━━━━━━━ 65s 418ms/step - accuracy: 0.9208 - loss: 0.2120 - val_accuracy: 0.8422 - val_loss: 0.3877
Epoch 4/5
157/157 ━━━━━━━━━━━━━━━━━━━━ 83s 425ms/step - accuracy: 0.9479 - loss: 0.1462 - val_accuracy: 0.8340 - val_loss: 0.4787
Epoch 5/5
157/157 ━━━━━━━━━━━━━━━━━━━━ 81s 418ms/step - accuracy: 0.9665 - loss: 0.1030 - val_accuracy: 0.8252 - val_loss: 0.4760
GRU Model Accuracy: 0.8253
